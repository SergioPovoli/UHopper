{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample\n",
    "import imblearn\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import glob\n",
    "from sklearn import svm\n",
    "import time \n",
    "\n",
    "def extract_month(month_str):\n",
    "    return int(month_str.split(\"-\")[1])\n",
    "\n",
    "def scaling(arr, type=\"standard\", perc_inf = 25, perc_sup = 75):\n",
    "    if type == \"standard\":\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "    elif type == \"robust\":\n",
    "        scaler = preprocessing.RobustScaler()\n",
    "        f.write(\"Scaling type not recognized\")\n",
    "        scaler= preprocessing.StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(np.array(arr).reshape(-1,1))\n",
    "    return scaled_features\n",
    "\n",
    "\n",
    "#ALL POSSIBILE OPTION IMPLEMENTED\n",
    "\n",
    "# nan_managing_options = [\"erase\",\"fill_mean\"]\n",
    "# normlaization_options = [\"standard\",\"robust\"]\n",
    "# training_balance_options = [\"minority\",\"smotenc\"]\n",
    "# type_of_arch_options = [\"ml\",\"dl\"]\n",
    "\n",
    "# OPTIONS USED DURINF TESTS FOR REDUCE TIME\n",
    "\n",
    "# nan_managing_options = [\"erase\",\"fill_mean\"]\n",
    "# normlaization_options = [\"robust\"]\n",
    "# training_balance_options = [\"smotenc\"]\n",
    "# type_of_arch_options = [\"ml\",\"dl\"]\n",
    "\n",
    "nan_managing_options = [\"erase\",\"fill_mean\"]\n",
    "normlaization_options = [\"robust\"]\n",
    "training_balance_options = [\"smotenc\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIFFERENT DATASET CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTION SELECTION\n",
    "for i in tqdm(range(len(nan_managing_options))):\n",
    "    nan_managing=nan_managing_options[i]\n",
    "    for j in range(len(normlaization_options)):\n",
    "        normalization=normlaization_options[j]\n",
    "        for k in range(len(training_balance_options)):\n",
    "            training_balance=training_balance_options[k]\n",
    "            \n",
    "            #create a dataframe with the options selected\n",
    "            options = pd.DataFrame({\"nan_managing\":nan_managing, \"normalization\":normalization, \"training_balance\":training_balance}, index=[0])\n",
    "\n",
    "            TEST_PATH = os.sep + os.path.join(\"workspace\", \"dataset_varius_test\",f\"{nan_managing}_{normalization}_{training_balance}\") \n",
    "            if not os.path.exists(TEST_PATH):\n",
    "                os.makedirs(TEST_PATH)\n",
    "\n",
    "            IMAGE_PATH = os.sep + os.path.join(TEST_PATH, \"Images\")\n",
    "            if not os.path.exists(IMAGE_PATH):\n",
    "                os.makedirs(IMAGE_PATH)\n",
    "\n",
    "            DATASET_PATH_TESTS = os.sep + os.path.join(TEST_PATH, \"dataset\")\n",
    "            if not os.path.exists(DATASET_PATH_TESTS):\n",
    "                os.makedirs(DATASET_PATH_TESTS)\n",
    "\n",
    "            options.to_csv(os.path.join(TEST_PATH, \"options.csv\"), index=False)\n",
    "\n",
    "            report_file_name = os.path.join(TEST_PATH,f\"report_dataset.txt\")\n",
    "            f = open(report_file_name, \"a\")\n",
    "\n",
    "            f.write(\"###########################################################\\n\")\n",
    "            f.write(\"############# STARTING NEW EXPERIMENT #####################\\n\")\n",
    "\n",
    "            f.write(\"\\n ---------- Options ---------- \\n\")\n",
    "\n",
    "            f.write(f\"Nan managing option: {nan_managing}\\n\")\n",
    "            f.write(f\"Normalization option:  {normalization}\\n\")\n",
    "            f.write(f\"Training balance option: {training_balance}\\n\")\n",
    "            \n",
    "\n",
    "            f.write(\"\\n ---------- READ DATA ---------- \\n\")\n",
    "\n",
    "            all_dataset_path = os.sep + os.path.join(\"workspace\", \"Dataset\", \"weather.csv\")\n",
    "            all_dataset_df = pd.read_csv(all_dataset_path)\n",
    "            f.write(\"Dataset has been read\\n\")\n",
    "\n",
    "\n",
    "            f.write(\"\\n ---------- MANAGE NAN ---------- \\n\")\n",
    "            f.write(\"Some info about the dataset:\\n\")\n",
    "            f.write(f\"| Len of all_dataset_df: {len(all_dataset_df)}\\n\")\n",
    "            f.write(f\"| Number of features: {len(all_dataset_df.columns)}\\n\")\n",
    "            not_nan_dataset_df = all_dataset_df.dropna(axis=0, how='any')\n",
    "            f.write(f\"| Len of not_nan_dataset_df:{ len(not_nan_dataset_df)}\\n\")\n",
    "            f.write(f\"| Only the {np.round(len(not_nan_dataset_df)/len(all_dataset_df),4)*100}% of the dataset is free of NaN values\")\n",
    "            f.write(\"-----------------------------------------------------\\n\")\n",
    "\n",
    "            nan_count_df = np.round(all_dataset_df.isnull().sum() * 100 / len(all_dataset_df),4).to_frame()\n",
    "            nan_count_df.columns = ['Percentage of NaN']\n",
    "\n",
    "            if nan_managing == \"erase\":\n",
    "                f.write(\"-->  Managing NaN values with erase\\n\")\n",
    "                #list of columns with NaN values > 30%\n",
    "                column_to_erase = nan_count_df[nan_count_df['Percentage of NaN'] > 30].index.to_list()\n",
    "                f.write(f\"The following columns have NaN values > 30%: {column_to_erase} and will be erased\\n\")\n",
    "                wo_somecolumun_dataset_df = all_dataset_df.drop(column_to_erase, axis=1)\n",
    "                not_nan_wo_somecolumn_dataset_df = wo_somecolumun_dataset_df.dropna(axis=0, how='any')\n",
    "                f.write(\"Any row of the remain dataset that contains at least one NaN values will be erased\\n\")\n",
    "                f.write(\"Final dataset lenght is {} and {}% of the initial dataset in terms of rows\\n\".format(len(not_nan_wo_somecolumn_dataset_df), np.round(len(not_nan_wo_somecolumn_dataset_df)/len(wo_somecolumun_dataset_df)*100,2)))\n",
    "                f.write(f\"Number of features of final dataset : {len(not_nan_wo_somecolumn_dataset_df.columns)}\\n\")\n",
    "                dataset_to_use = not_nan_wo_somecolumn_dataset_df\n",
    "\n",
    "                categorical_column = []\n",
    "                non_categorical_column=[]\n",
    "\n",
    "                for i in dataset_to_use.columns:\n",
    "                    \n",
    "                    if dataset_to_use[i].dtype == 'object':\n",
    "                        categorical_column.append(i)\n",
    "                    else:\n",
    "                        non_categorical_column.append(i)\n",
    "\n",
    "                f.write(f\"The final dataset contains the following categorical columns: {categorical_column}\\n\")\n",
    "                f.write(f\"The final dataset contains the following non-categorical columns: {non_categorical_column}\\n\")\n",
    "                        \n",
    "            elif nan_managing == \"fill_mean\":\n",
    "                f.write(\"--> Managing NaN values with fill_mean\\n\")\n",
    "                f.write(\"Categorical colum will be fill with the mode of the column, while, numerical columns will be fill with the mean\\n\")\n",
    "\n",
    "\n",
    "                categorical_column = []\n",
    "                non_categorical_column=[]\n",
    "\n",
    "                for i in all_dataset_df.columns:\n",
    "                    \n",
    "                    if all_dataset_df[i].dtype == 'object':\n",
    "                        categorical_column.append(i)\n",
    "                    else:\n",
    "                        non_categorical_column.append(i)\n",
    "\n",
    "                dataset_to_use = all_dataset_df\n",
    "\n",
    "                for i in categorical_column:\n",
    "                    dataset_to_use[i] = dataset_to_use[i].fillna(dataset_to_use[i].mode()[0])\n",
    "                for i in non_categorical_column:\n",
    "                    dataset_to_use[i] = dataset_to_use[i].fillna(dataset_to_use[i].mean())\n",
    "\n",
    "                f.write(\"The final dataset lenght is {} and {}% of the initial dataset in terms of rows\\n\".format(len(dataset_to_use), np.round(len(dataset_to_use)/len(all_dataset_df)*100,2)))\n",
    "                f.write(f\"Number of features of final dataset : {len(dataset_to_use.columns)}\\n\")\n",
    "\n",
    "                f.write(f\"The final dataset contains the following categorical columns: {categorical_column}\\n\")\n",
    "                f.write(f\"The final dataset contains the following non-categorical columns: {non_categorical_column}\\n\")\n",
    "\n",
    "            f.write(\"\\n---------- ENCODING DATA ---------- \\n\")\n",
    "\n",
    "            categorical_column = []\n",
    "            non_categorical_column=[]\n",
    "\n",
    "            for i in dataset_to_use.columns:\n",
    "                \n",
    "                if dataset_to_use[i].dtype == 'object':\n",
    "                    categorical_column.append(i)\n",
    "                else:\n",
    "                    non_categorical_column.append(i)\n",
    "\n",
    "            dataset_to_use = dataset_to_use.replace(['No', 'Yes'], [0, 1])\n",
    "            f.write(\"The Yes and No values have been replaced by 1 and 0\\n\")\n",
    "            f.write(\"The Date columns have been dropped and an additional column with month has been added\\n\")\n",
    "            f.write(\"Other categorical columns have been encoded with LabelEncoder: the mapping is saved in a csv file\\n\")\n",
    "\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            for i in categorical_column:\n",
    "                if i != 'Date':\n",
    "                    dataset_to_use[i] = le.fit_transform(dataset_to_use[i])\n",
    "                    mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "                    mapping_df = pd.DataFrame(mapping.items(), columns=['Original', 'Encoded'])\n",
    "                    mapping_df.to_csv(os.path.join(DATASET_PATH_TESTS, \"mapping_\" + i + \"_OPTIONS_\"+ str(nan_managing) + \".csv\"))\n",
    "                    f.write(f\"{i} has been encoded, mapping saved in {DATASET_PATH_TESTS}/mapping_{i}_OPTIONS_{nan_managing}.csv\\n\")\n",
    "                else:\n",
    "                    dataset_to_use[\"month\"] = dataset_to_use[\"Date\"].apply(extract_month)\n",
    "                    dataset_to_use.drop([\"Date\"], axis=1, inplace=True)\n",
    "\n",
    "            dataset_to_use.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "            f.write(\"The Unnamed: 0 column has been dropped\\n\")\n",
    "\n",
    "            f.write(\"\\n ---------- CHECK CLASS DISTIRBUTION ---------- \\n\")\n",
    "\n",
    "            tw_rain = np.sum(np.array(dataset_to_use[\"RainTomorrow\"]))\n",
    "            tw_not_rain = len(dataset_to_use) - tw_rain\n",
    "            tw_rain_perc = np.round(tw_rain/len(dataset_to_use)*100,2)\n",
    "            tw_not_rain_perc = np.round(tw_not_rain/len(dataset_to_use)*100,2)\n",
    "\n",
    "            f.write(f\"RainTomorrow: {tw_rain}, that is the {tw_rain_perc}% of the dataset\\n\")\n",
    "            f.write(f\"NotRainTomorrow: {tw_not_rain}, that is the {tw_not_rain_perc}% of the dataset\\n\")\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(15,10))\n",
    "            plt.rcParams.update({'font.size': 15})\n",
    "            ax.bar(['1', '0'], [tw_rain, tw_not_rain],color=[(0.95,0.11,0.41), (0.12,0.07,0.3)])\n",
    "            #add second y-axis\n",
    "            ax2 = ax.twinx()\n",
    "            ax2.bar(['1', '0'], [tw_rain_perc, tw_not_rain_perc], color=[(0.95,0.11,0.41), (0.12,0.07,0.3)])\n",
    "            ax2.set_ylabel('Percentage of all dataset')\n",
    "            ax.set_title(\"RainTomorrow Columns\")\n",
    "            ax.set_ylabel(\"Number of Samples\")\n",
    "            plt.grid(True)\n",
    "            # add capiton under th plot \n",
    "            plt.savefig(os.path.join(IMAGE_PATH,f\"BarPlot_Distirbution_RainTomorrow_OPTIONS_{nan_managing}.png\"), dpi=300)\n",
    "            plt.close()\n",
    "            f.write(f\"Bar plot of RainTomorrow has been saved in {IMAGE_PATH}/BarPlot_Distirbution_RainTomorrow_OPTIONS_{nan_managing}.png\\n\")\n",
    "\n",
    "            f.write(\"\\n ---------- NORMALZIE DATA ---------- \\n\")\n",
    "\n",
    "            featuers = dataset_to_use.drop(['RainTomorrow'], axis=1)\n",
    "            target = dataset_to_use['RainTomorrow']\n",
    "\n",
    "            plt.figure(figsize=(20,10))\n",
    "            sns.boxplot(data = featuers)\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.savefig(os.path.join(IMAGE_PATH,f\"BoxPlot_features_distribution_OPTIONS_{nan_managing}.png\"), dpi=300)\n",
    "            plt.close()\n",
    "            f.write(f\"Box plot of features distribution has been saved in {IMAGE_PATH}/BoxPlot_features_distribution_OPTIONS_{nan_managing}.png\\n\")\n",
    "\n",
    "\n",
    "            if normalization == \"standard\":\n",
    "                f.write(\"--> Normalizing data with StandardScaler\\n\")\n",
    "                scaled_features = featuers\n",
    "                for i in featuers.columns:\n",
    "                    scaled_features[i] = scaling(scaled_features[i])\n",
    "\n",
    "                plt.figure(figsize=(20,10))\n",
    "                sns.boxplot(data = scaled_features)\n",
    "                plt.xticks(rotation=90)\n",
    "                plt.savefig(os.path.join(IMAGE_PATH,f\"BoxPlot_features_distribution_StandardScaler_OPTIONS_{nan_managing}_{normalization}.png\"), dpi=300)\n",
    "                plt.close()\n",
    "                f.write(f\"Box plot of features distribution has been saved in {IMAGE_PATH}/BoxPlot_features_distribution_StandardScaler_OPTIONS_{nan_managing}_{normalization}.png\\n\")\n",
    "\n",
    "                featuers = scaled_features\n",
    "\n",
    "            elif normalization == \"robust\":\n",
    "                f.write(\"--> Normalizing data with Scaler and quantile remove\\n\")\n",
    "                inf_quantile = 0.05\n",
    "                sup_quantile = 0.95\n",
    "\n",
    "                f.write(f\"Inf qunatile: {inf_quantile}\\n\")\n",
    "                f.write(f\"Sup qunatile: {sup_quantile}\\n\")\n",
    "\n",
    "                scaled_features = featuers\n",
    "                for i in featuers.columns:\n",
    "                    scaled_features[i] = scaling(scaled_features[i])\n",
    "\n",
    "                scaled_features_quantile = scaled_features\n",
    "                for i in scaled_features.columns:\n",
    "                    if i not in categorical_column:\n",
    "                        quantilie_inf = np.quantile(scaled_features[i], inf_quantile)\n",
    "                        quantilie_sup = np.quantile(scaled_features[i], sup_quantile)\n",
    "                        scaled_features_quantile[i] = scaled_features[i].apply(lambda x: np.clip(x, quantilie_inf, quantilie_sup))\n",
    "\n",
    "                plt.figure(figsize=(20,10))\n",
    "                sns.boxplot(data = scaled_features_quantile)\n",
    "                plt.xticks(rotation=90)\n",
    "                plt.savefig(os.path.join(IMAGE_PATH,f\"BoxPlot_features_distribution_RobustScaler_OPTIONS_{nan_managing}_{normalization}.png\"), dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "                featuers = scaled_features_quantile\n",
    "\n",
    "            f.write(\"\\n --------SPLITTING------------ \\n\")\n",
    "\n",
    "            f.write(\"--> Splitting data in order to create a balanced TEST dataset\\n\")\n",
    "            test_size = 0.3 # 30% of the smallest class in the dataset\n",
    "            f.write(f\"Test size is the {test_size*100}% of the smallest class in the dataset multply bt the number of classes\\n\")\n",
    "            yes_num = np.sum(target)\n",
    "            no_num = len(target) - yes_num\n",
    "            test_size_samples_for_each_class = int(np.round(test_size*yes_num))\n",
    "            f.write(f\"Number of samples for each class: {test_size_samples_for_each_class}\\n\")\n",
    "\n",
    "            #join the target and the features\n",
    "            features_target = pd.concat([featuers, target], axis=1)\n",
    "            #shuffle the data\n",
    "            features_target = features_target.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "            test_yes = features_target[features_target[\"RainTomorrow\"] == 1].iloc[0:test_size_samples_for_each_class,:]\n",
    "            train_yes = features_target[features_target[\"RainTomorrow\"] == 1].iloc[test_size_samples_for_each_class:,:]\n",
    "            test_no = features_target[features_target[\"RainTomorrow\"] == 0].iloc[0:test_size_samples_for_each_class,:]\n",
    "            train_no = features_target[features_target[\"RainTomorrow\"] == 0].iloc[test_size_samples_for_each_class:,:]\n",
    "\n",
    "            train = pd.concat([train_yes, train_no], axis=0)\n",
    "            test = pd.concat([test_yes, test_no], axis=0)\n",
    "\n",
    "            f.write(\"\\nFrom the whole dataset we will extract {test_size_samples_for_each_class} samples for each class in order to have a balanced TEST dataset\")\n",
    "            f.write(\"\\nThe train dataset will contain {len(train)} samples and the dataset isn't balanced\")\n",
    "\n",
    "            f.write(\"\\nNumber of samples in test: {}\".format(len(test)))\n",
    "            f.write(\"\\nTest set is {}% of the dataset\".format(np.round(len(test)/len(features_target)*100,2)))\n",
    "\n",
    "            fig, ax = plt.subplots(1,2, figsize=(15,10))\n",
    "            plt.rcParams.update({'font.size': 15})\n",
    "            #set y axes to the same scale for ax[0] and ax[1]\n",
    "            ax[0].bar(['Yes', 'No'], [len(train_yes), len(train_no)], color=[(0.95,0.11,0.41), (0.12,0.07,0.3)])\n",
    "            ax[0].set_title(\"Train set\")\n",
    "            ax[0].set_xlabel(\"RainTomorrow\")\n",
    "            ax[0].set_ylabel(\"Number of Samples\")\n",
    "            ax[0].grid(True)\n",
    "\n",
    "            ax[1].bar(['Yes', 'No'], [len(test_yes), len(test_no)],color=[(0.95,0.11,0.41), (0.12,0.07,0.3)])\n",
    "            ax[1].set_title(\"Test set\")\n",
    "            ax[1].set_xlabel(\"RainTomorrow\")\n",
    "            ax[1].set_ylabel(\"Number of Samples\")\n",
    "            ax[1].set_ylim(ax[0].get_ylim())\n",
    "            ax[1].grid(True)\n",
    "            plt.suptitle(\"Train and Test set before oversampling\")\n",
    "            plt.savefig(os.path.join(IMAGE_PATH,f\"Train_Test_dataset_barplot_distirbution_OPTIONS_{nan_managing}_{normalization}.png\"), dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            f.write(\"\\n ---------- BALANCE TRAINING DATA ---------- \\n\")\n",
    "\n",
    "            train_featuers = train.drop(['RainTomorrow'], axis=1)\n",
    "            train_target = train['RainTomorrow']\n",
    "\n",
    "            categorical = categorical_column\n",
    "            categorical.remove('Date')\n",
    "            categorical.remove('RainTomorrow')\n",
    "            categorical_mask = []\n",
    "\n",
    "            for i in train_featuers.columns:\n",
    "                if i in categorical:\n",
    "                    categorical_mask.append(True)\n",
    "                else:\n",
    "                    categorical_mask.append(False)\n",
    "\n",
    "            if training_balance == \"minority\":\n",
    "                f.write(\"\\n--> Balancing training data with the minority class\")\n",
    "                oversample = imblearn.over_sampling.RandomOverSampler(sampling_strategy='minority')\n",
    "            elif training_balance == \"smotenc\":\n",
    "                f.write(\"\\n--> Balancing training data with SMOTE\")\n",
    "                oversample = imblearn.over_sampling.SMOTENC(categorical_features=categorical_mask,sampling_strategy='minority',random_state=42)\n",
    "\n",
    "            train_featuers_resampled, train_target_resampled = oversample.fit_resample(train_featuers, train_target)\n",
    "\n",
    "            #create dataframe from resampled data\n",
    "            train_resampled = train_featuers_resampled\n",
    "            train_resampled['RainTomorrow'] = train_target_resampled\n",
    "\n",
    "            tw_rain = np.sum(np.array(train_resampled[\"RainTomorrow\"]))\n",
    "            tw_not_rain = len(train_resampled) - tw_rain\n",
    "            tw_rain_perc = np.round(tw_rain/len(train_resampled)*100,2)\n",
    "            tw_not_rain_perc = np.round(tw_not_rain/len(train_resampled)*100,2)\n",
    "\n",
    "            f.write(f\"\\nRainTomorrow in training: {tw_rain}, that is the {tw_rain_perc}% of the dataset oversampled\")\n",
    "            f.write(f\"\\nNotRainTomorrow in training: {tw_not_rain}, that is the {tw_not_rain_perc}% of the dataset oversampled\")\n",
    "\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(15,10))\n",
    "            plt.rcParams.update({'font.size': 15})\n",
    "            ax.bar(['1', '0'], [tw_rain, tw_not_rain], color=[(0.95,0.11,0.41), (0.12,0.07,0.3)])\n",
    "            #add second y-axis\n",
    "            ax2 = ax.twinx()\n",
    "            ax2.bar(['1', '0'], [tw_rain_perc, tw_not_rain_perc], color=[(0.95,0.11,0.41), (0.12,0.07,0.3)])\n",
    "            ax2.set_ylabel('Percentage of all train dataset')\n",
    "            ax.set_title(\"RainTomorrow Columns Oversampled DF\")\n",
    "            ax.set_ylabel(\"Number of Samples\")\n",
    "            plt.grid(True)\n",
    "            # add capiton under th plot \n",
    "            plt.savefig(os.path.join(IMAGE_PATH,F\"BarPlot_Distirbution_RainTomorrow_train_oversampled_OPTIONS_{nan_managing}_{normalization}_{training_balance}.png\"), dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            f.write(f\"\\nDataset dimension increased by: {len(train_resampled)-len(train)}\")\n",
    "\n",
    "            x_train  = train_resampled.drop(['RainTomorrow'], axis=1)\n",
    "            y_train = train_resampled['RainTomorrow']\n",
    "            x_test = test.drop(['RainTomorrow'], axis=1)\n",
    "            y_test = test['RainTomorrow']\n",
    "\n",
    "            #save the train and test dataset\n",
    "            x_train.to_csv(os.path.join(DATASET_PATH_TESTS,\"x_train.csv\"), index=False)\n",
    "            y_train.to_csv(os.path.join(DATASET_PATH_TESTS,\"y_train.csv\"), index=False)\n",
    "            x_test.to_csv(os.path.join(DATASET_PATH_TESTS,\"x_test.csv\"), index=False)\n",
    "            y_test.to_csv(os.path.join(DATASET_PATH_TESTS,\"y_test.csv\"), index=False)\n",
    "            f.write(\"\\nDataset saved at {}\".format(DATASET_PATH_TESTS))\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(25,10))\n",
    "            plt.rcParams.update({'font.size': 15})\n",
    "            sns.heatmap(featuers.corr(), annot=True, ax=ax, cmap='RdBu_r')\n",
    "            ax.set_title(\"Correlation Matrix\")\n",
    "            ax.set_xlabel(\"Features\")\n",
    "            ax.set_ylabel(\"Features\")\n",
    "            plt.savefig(os.path.join(IMAGE_PATH,F\"Correlation_Matrix_OPTIONS_{nan_managing}_{normalization}_{training_balance}.png\"), dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "            f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT ON DIFFERENT DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = os.path.sep + os.path.join(\"workspace\", \"dataset_varius_test\")\n",
    "for dataset_folder in os.listdir(DATASETS_PATH):\n",
    "    folder = os.path.join(DATASETS_PATH, dataset_folder)\n",
    "    RESULTS_PATH = os.path.sep + os.path.join(\"workspace\", \"results\", dataset_folder + \"_RF\")\n",
    "\n",
    "    if not os.path.exists(RESULTS_PATH):\n",
    "        os.makedirs(RESULTS_PATH)\n",
    "\n",
    "    x_train_path = glob.glob(os.path.join(folder, \"dataset\", \"x_train.csv\"))\n",
    "    y_train_path = glob.glob(os.path.join(folder, \"dataset\", \"y_train.csv\"))\n",
    "    x_test_path  = glob.glob(os.path.join(folder, \"dataset\", \"x_test.csv\"))\n",
    "    y_test_path  = glob.glob(os.path.join(folder, \"dataset\", \"y_test.csv\"))\n",
    "\n",
    "    x_train = pd.read_csv(x_train_path[0])\n",
    "    y_train = pd.read_csv(y_train_path[0])\n",
    "    x_test  = pd.read_csv(x_test_path[0])\n",
    "    y_test  = pd.read_csv(y_test_path[0])\n",
    "\n",
    "    ml = RandomForestClassifier(n_estimators = 100, random_state = 0)\n",
    "    ml.fit(x_train, y_train)\n",
    "    joblib.dump(ml, os.path.join(RESULTS_PATH, \"model.joblib\"))\n",
    "\n",
    "    st = time.time()\n",
    "    y_pred = ml.predict(x_test)\n",
    "    ed = time.time()\n",
    "    ex_time = ed - st\n",
    "    sps = len(y_pred)/ex_time\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=[\"Not Rain\", \"Rain\"])\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    df_res = pd.DataFrame({\"Precision\": [precision], \"Recall\": [recall], \"F1\": [f1], \"Accuracy\": [acc], \"Execution Time\": [ex_time], \"Samples per second\": [sps], \"Classification Report\": [report]})\n",
    "    df_res.to_csv(os.path.join(RESULTS_PATH, \"results.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = os.path.sep + os.path.join(\"workspace\", \"dataset_varius_test\")\n",
    "for dataset_folder in os.listdir(DATASETS_PATH):\n",
    "    folder = os.path.join(DATASETS_PATH, dataset_folder)\n",
    "    RESULTS_PATH = os.path.sep + os.path.join(\"workspace\", \"results\", dataset_folder + \"_LR\")\n",
    "\n",
    "    if not os.path.exists(RESULTS_PATH):\n",
    "        os.makedirs(RESULTS_PATH)\n",
    "\n",
    "    x_train_path = glob.glob(os.path.join(folder, \"dataset\", \"x_train.csv\"))\n",
    "    y_train_path = glob.glob(os.path.join(folder, \"dataset\", \"y_train.csv\"))\n",
    "    x_test_path  = glob.glob(os.path.join(folder, \"dataset\", \"x_test.csv\"))\n",
    "    y_test_path  = glob.glob(os.path.join(folder, \"dataset\", \"y_test.csv\"))\n",
    "\n",
    "    x_train = pd.read_csv(x_train_path[0])\n",
    "    y_train = pd.read_csv(y_train_path[0])\n",
    "    x_test  = pd.read_csv(x_test_path[0])\n",
    "    y_test  = pd.read_csv(y_test_path[0])\n",
    "\n",
    "    ml = LogisticRegression()\n",
    "    ml.fit(x_train, y_train)\n",
    "    joblib.dump(ml, os.path.join(RESULTS_PATH, \"model.joblib\"))\n",
    "\n",
    "    st = time.time()\n",
    "    y_pred = ml.predict(x_test)\n",
    "    ed = time.time()\n",
    "    ex_time = ed - st\n",
    "    sps = len(y_pred)/ex_time\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=[\"Not Rain\", \"Rain\"])\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    df_res = pd.DataFrame({\"Precision\": [precision], \"Recall\": [recall], \"F1\": [f1], \"Accuracy\": [acc], \"Execution Time\": [ex_time], \"Samples per second\": [sps], \"Classification Report\": [report]})\n",
    "    df_res.to_csv(os.path.join(RESULTS_PATH, \"results.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = os.path.sep + os.path.join(\"workspace\", \"dataset_varius_test\")\n",
    "for dataset_folder in os.listdir(DATASETS_PATH):\n",
    "    folder = os.path.join(DATASETS_PATH, dataset_folder)\n",
    "    RESULTS_PATH = os.path.sep + os.path.join(\"workspace\", \"results\", dataset_folder + \"_svm1_1\")\n",
    "\n",
    "    if not os.path.exists(RESULTS_PATH):\n",
    "        os.makedirs(RESULTS_PATH)\n",
    "\n",
    "    x_train_path = glob.glob(os.path.join(folder, \"dataset\", \"x_train.csv\"))\n",
    "    y_train_path = glob.glob(os.path.join(folder, \"dataset\", \"y_train.csv\"))\n",
    "    x_test_path  = glob.glob(os.path.join(folder, \"dataset\", \"x_test.csv\"))\n",
    "    y_test_path  = glob.glob(os.path.join(folder, \"dataset\", \"y_test.csv\"))\n",
    "\n",
    "    x_train = pd.read_csv(x_train_path[0])\n",
    "    y_train = pd.read_csv(y_train_path[0])\n",
    "    x_test  = pd.read_csv(x_test_path[0])\n",
    "    y_test  = pd.read_csv(y_test_path[0])\n",
    "\n",
    "    weights_per_class = [1,1]\n",
    "    class_weight_d = {0: weights_per_class[0], 1: weights_per_class[1]}\n",
    "    ml = svm.SVC(class_weight=class_weight_d)\n",
    "\n",
    "    ml.fit(x_train, y_train)\n",
    "    joblib.dump(ml, os.path.join(RESULTS_PATH, \"model.joblib\"))\n",
    "\n",
    "    st = time.time()\n",
    "    y_pred = ml.predict(x_test)\n",
    "    ed = time.time()\n",
    "    ex_time = ed - st\n",
    "    sps = len(y_pred)/ex_time\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=[\"Not Rain\", \"Rain\"])\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    df_res = pd.DataFrame({\"Precision\": [precision], \"Recall\": [recall], \"F1\": [f1], \"Accuracy\": [acc], \"Execution Time\": [ex_time], \"Samples per second\": [sps], \"Classification Report\": [report]})\n",
    "    df_res.to_csv(os.path.join(RESULTS_PATH, \"results.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = os.path.sep + os.path.join(\"workspace\", \"dataset_varius_test\")\n",
    "for dataset_folder in os.listdir(DATASETS_PATH):\n",
    "    folder = os.path.join(DATASETS_PATH, dataset_folder)\n",
    "    RESULTS_PATH = os.path.sep + os.path.join(\"workspace\", \"results\", dataset_folder + \"_svm1_1.2\")\n",
    "\n",
    "    if not os.path.exists(RESULTS_PATH):\n",
    "        os.makedirs(RESULTS_PATH)\n",
    "\n",
    "    x_train_path = glob.glob(os.path.join(folder, \"dataset\", \"x_train.csv\"))\n",
    "    y_train_path = glob.glob(os.path.join(folder, \"dataset\", \"y_train.csv\"))\n",
    "    x_test_path  = glob.glob(os.path.join(folder, \"dataset\", \"x_test.csv\"))\n",
    "    y_test_path  = glob.glob(os.path.join(folder, \"dataset\", \"y_test.csv\"))\n",
    "\n",
    "    x_train = pd.read_csv(x_train_path[0])\n",
    "    y_train = pd.read_csv(y_train_path[0])\n",
    "    x_test  = pd.read_csv(x_test_path[0])\n",
    "    y_test  = pd.read_csv(y_test_path[0])\n",
    "\n",
    "    weights_per_class = [1,1.2]\n",
    "    class_weight_d = {0: weights_per_class[0], 1: weights_per_class[1]}\n",
    "    ml = svm.SVC(class_weight=class_weight_d)\n",
    "\n",
    "    ml.fit(x_train, y_train)\n",
    "    joblib.dump(ml, os.path.join(RESULTS_PATH, \"model.joblib\"))\n",
    "\n",
    "    st = time.time()\n",
    "    y_pred = ml.predict(x_test)\n",
    "    ed = time.time()\n",
    "    ex_time = ed - st\n",
    "    sps = len(y_pred)/ex_time\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=[\"Not Rain\", \"Rain\"])\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    df_res = pd.DataFrame({\"Precision\": [precision], \"Recall\": [recall], \"F1\": [f1], \"Accuracy\": [acc], \"Execution Time\": [ex_time], \"Samples per second\": [sps], \"Classification Report\": [report]})\n",
    "    df_res.to_csv(os.path.join(RESULTS_PATH, \"results.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import glob \n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassification(nn.Module):\n",
    "    def __init__(self,input_shape, n_classes=1, hidden_1 = 64, hidden_2 = 64, dropout = 0.5,batch_size=64):\n",
    "            super(BinaryClassification, self).__init__()\n",
    "            self.layer_1 = nn.Linear(input_shape, hidden_1) \n",
    "            self.layer_2 = nn.Linear(hidden_1, hidden_2)\n",
    "            self.layer_out = nn.Linear(hidden_2, n_classes) \n",
    "            self.layer_out_put = nn.Sigmoid()\n",
    "            \n",
    "            self.relu = nn.ReLU()\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "            self.batchnorm1 = nn.BatchNorm1d(hidden_2)\n",
    "            self.batchnorm2 = nn.BatchNorm1d(hidden_2)\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        #------------------------------------------------------\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        #------------------------------------------------------\n",
    "        x = self.layer_out(x)\n",
    "        out = self.layer_out_put(x)\n",
    "        \n",
    "        return out   \n",
    "\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = y_pred.squeeze()\n",
    "    correct_results_sum = (y_pred_tag == y_test.squeeze()).sum().float()\n",
    "    acc = correct_results_sum/len(y_test.squeeze())    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, x_train_path, y_train_path):\n",
    "        self.x_train_path = x_train_path\n",
    "        self.y_train_path = y_train_path\n",
    "        self.x_train = pd.read_csv(self.x_train_path)\n",
    "        self.y_train = pd.read_csv(self.y_train_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'sample': self.x_train.iloc[idx].values, \n",
    "                'label': self.y_train.iloc[idx].values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, loader, device, criterion):\n",
    "    n_val = len(loader)\n",
    "    tot_loss = 0\n",
    "    tot_acc = 0\n",
    "\n",
    "    with tqdm(total=n_val, desc='Validation round', unit='batch',disable = True, leave=True) as pbar:\n",
    "        for batch in loader:\n",
    "            sample = batch['sample'].to(device).float()\n",
    "            label = batch['label'].to(device).float()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_pred = net(sample)\n",
    "                y_pred_tag = torch.round(y_pred)\n",
    "            \n",
    "            loss = criterion(y_pred, label)\n",
    "            acc = binary_acc(y_pred_tag, label.unsqueeze(1))\n",
    "\n",
    "            tot_loss += loss.item()\n",
    "            tot_acc += acc.item()\n",
    "\n",
    "            pbar.set_postfix(**{'Val Loss/batch': loss, 'Val Acc/batch': acc})\n",
    "            pbar.update()\n",
    "    net.train()\n",
    "    return tot_loss/len(loader), tot_acc/len(loader)\n",
    "\n",
    "\n",
    "def train_net (net,device,x_train_path,y_train_path, dir_checkpoint, epochs=5,batch_size = 1, lr = 0.001 ):\n",
    "    dataset = myDataset(x_train_path,y_train_path)\n",
    "    #split dataset into train and test\n",
    "    train_size = int(0.9 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    writer = SummaryWriter(comment=f'LR_{lr}_BS_{batch_size}_EP_{epochs}')\n",
    "    global_step = 0\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        pseudo_batch_loss = 0\n",
    "        pseudo_batch_acc = 0\n",
    "        \n",
    "        with tqdm(total=len(train_loader), desc=f'Epoch {epoch}/{epochs}') as pbar:\n",
    "            for batch in train_loader:\n",
    "                sample = batch['sample'].to(device).float()\n",
    "                label = batch['label'].to(device).float()\n",
    "\n",
    "                y_pred = net(sample)\n",
    "                \n",
    "                loss = criterion(y_pred, label)\n",
    "                acc = binary_acc(torch.round(y_pred), label.unsqueeze(1))\n",
    "\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_acc += acc.item()\n",
    "                global_step += 1\n",
    "                pseudo_batch_loss += loss.item()\n",
    "                pseudo_batch_acc += acc.item()\n",
    "\n",
    "                if (global_step) % 1 == 0:\n",
    "                    writer.add_scalar('Loss/train each batch', pseudo_batch_loss, global_step)\n",
    "                    writer.add_scalar('Acc/train each batch', pseudo_batch_acc, global_step)\n",
    "                    pbar.set_postfix(**{'loss': pseudo_batch_loss, 'acc': pseudo_batch_acc})\n",
    "                    pseudo_batch_acc = 0\n",
    "                    pseudo_batch_loss = 0\n",
    "                    \n",
    "                pbar.update()\n",
    "\n",
    "        loss_val, acc_val = eval_net(net, val_loader, device, criterion)\n",
    "        scheduler.step(acc_val)\n",
    "\n",
    "        writer.add_scalar('Loss/val', loss_val, epoch)\n",
    "        writer.add_scalar('Acc/val', acc_val, epoch)\n",
    "        writer.add_scalar('Acc/train epoches', epoch_acc/len(train_loader), epoch)\n",
    "        writer.add_scalar('Loss/train epoches', epoch_loss/len(train_loader), epoch)\n",
    "\n",
    "        if(epoch % 2 == 0):\n",
    "            try:\n",
    "                os.mkdir(dir_checkpoint)\n",
    "                logging.info('Created checkpoint directory')\n",
    "            except OSError:\n",
    "                pass\n",
    "            torch.save(net.state_dict(), os.path.join(dir_checkpoint,f\"net_epoch_{epoch}.pth\"))\n",
    "    \n",
    "        \n",
    "            \n",
    "    torch.save(net.state_dict(), os.path.join(dir_checkpoint,f\"net_epoch_{epochs}.pth\"))\n",
    "\n",
    "def prediction(net,\n",
    "                device,\n",
    "                x_test_path,\n",
    "                y_test_path):\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    test_dataset =myDataset(x_test_path,y_test_path)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, pin_memory=True)\n",
    "\n",
    "    label_t = []\n",
    "    pred_t = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Batch' ) as pbar:\n",
    "        for batch in test_loader:\n",
    "            sample = batch['sample'].to(device).float()\n",
    "            label = batch['label'].to(device).float()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_pred = net(sample)\n",
    "                y_pred_tag = torch.round(y_pred)\n",
    "\n",
    "        \n",
    "            label_t.append(label.cpu().numpy().squeeze().tolist())\n",
    "            pred_t.append(np.round(y_pred_tag.cpu().numpy()).squeeze().tolist())\n",
    "            pbar.update()\n",
    "            \n",
    "    return label_t, pred_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 19126/19126 [00:14<00:00, 1363.22it/s]\n",
      "Epoch 0/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.87it/s, acc=0.85, loss=0.542] \n",
      "Epoch 1/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.75it/s, acc=0.812, loss=0.617]\n",
      "Epoch 2/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.91it/s, acc=0.8, loss=0.536]  \n",
      "Epoch 3/100: 100%|██████████| 1131/1131 [00:23<00:00, 48.11it/s, acc=0.825, loss=0.623]\n",
      "Epoch 4/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.81it/s, acc=0.762, loss=0.648]\n",
      "Epoch 5/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.80it/s, acc=0.825, loss=0.574]\n",
      "Epoch 6/100: 100%|██████████| 1131/1131 [00:23<00:00, 48.14it/s, acc=0.663, loss=0.645]\n",
      "Epoch 7/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.69it/s, acc=0.8, loss=0.616]  \n",
      "Epoch 8/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.38it/s, acc=0.863, loss=0.587]\n",
      "Epoch 9/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.14it/s, acc=0.762, loss=0.592]\n",
      "Epoch 10/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.31it/s, acc=0.863, loss=0.56] \n",
      "Epoch 11/100: 100%|██████████| 1131/1131 [00:24<00:00, 47.09it/s, acc=0.838, loss=0.558]\n",
      "Epoch 12/100: 100%|██████████| 1131/1131 [00:21<00:00, 53.74it/s, acc=0.85, loss=0.577] \n",
      "Epoch 13/100: 100%|██████████| 1131/1131 [00:20<00:00, 56.08it/s, acc=0.762, loss=0.607]\n",
      "Epoch 14/100: 100%|██████████| 1131/1131 [00:20<00:00, 56.20it/s, acc=0.725, loss=0.64] \n",
      "Epoch 15/100: 100%|██████████| 1131/1131 [00:20<00:00, 55.89it/s, acc=0.825, loss=0.613]\n",
      "Epoch 16/100: 100%|██████████| 1131/1131 [00:20<00:00, 56.10it/s, acc=0.8, loss=0.615]  \n",
      "Epoch 17/100: 100%|██████████| 1131/1131 [00:20<00:00, 56.19it/s, acc=0.788, loss=0.572]\n",
      "Epoch 18/100: 100%|██████████| 1131/1131 [00:20<00:00, 56.09it/s, acc=0.85, loss=0.563] \n",
      "Epoch 19/100: 100%|██████████| 1131/1131 [00:20<00:00, 56.20it/s, acc=0.7, loss=0.586]  \n",
      "Epoch 20/100: 100%|██████████| 1131/1131 [00:20<00:00, 56.46it/s, acc=0.8, loss=0.568]  \n",
      "Epoch 21/100: 100%|██████████| 1131/1131 [00:20<00:00, 55.97it/s, acc=0.875, loss=0.58] \n",
      "Epoch 22/100: 100%|██████████| 1131/1131 [00:20<00:00, 56.12it/s, acc=0.812, loss=0.574]\n",
      "Epoch 23/100: 100%|██████████| 1131/1131 [00:20<00:00, 56.23it/s, acc=0.713, loss=0.61] \n",
      "Epoch 24/100: 100%|██████████| 1131/1131 [00:20<00:00, 55.93it/s, acc=0.788, loss=0.595]\n",
      "Epoch 25/100: 100%|██████████| 1131/1131 [00:22<00:00, 50.25it/s, acc=0.775, loss=0.589]\n",
      "Epoch 26/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.86it/s, acc=0.788, loss=0.578]\n",
      "Epoch 27/100: 100%|██████████| 1131/1131 [00:24<00:00, 47.09it/s, acc=0.788, loss=0.581]\n",
      "Epoch 28/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.84it/s, acc=0.838, loss=0.57] \n",
      "Epoch 29/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.84it/s, acc=0.875, loss=0.532]\n",
      "Epoch 30/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.66it/s, acc=0.75, loss=0.603] \n",
      "Epoch 31/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.24it/s, acc=0.812, loss=0.594]\n",
      "Epoch 32/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.45it/s, acc=0.825, loss=0.556]\n",
      "Epoch 33/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.71it/s, acc=0.875, loss=0.568]\n",
      "Epoch 34/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.86it/s, acc=0.825, loss=0.544]\n",
      "Epoch 35/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.32it/s, acc=0.788, loss=0.609]\n",
      "Epoch 36/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.50it/s, acc=0.825, loss=0.593]\n",
      "Epoch 37/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.90it/s, acc=0.863, loss=0.59] \n",
      "Epoch 38/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.55it/s, acc=0.875, loss=0.576]\n",
      "Epoch 39/100: 100%|██████████| 1131/1131 [00:23<00:00, 48.51it/s, acc=0.8, loss=0.608]  \n",
      "Epoch 40/100: 100%|██████████| 1131/1131 [00:24<00:00, 45.81it/s, acc=0.85, loss=0.549] \n",
      "Epoch 41/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.44it/s, acc=0.775, loss=0.629]\n",
      "Epoch 42/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.97it/s, acc=0.85, loss=0.583] \n",
      "Epoch 43/100: 100%|██████████| 1131/1131 [00:23<00:00, 48.09it/s, acc=0.863, loss=0.538]\n",
      "Epoch 44/100: 100%|██████████| 1131/1131 [00:24<00:00, 45.95it/s, acc=0.875, loss=0.588]\n",
      "Epoch 45/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.19it/s, acc=0.8, loss=0.562]  \n",
      "Epoch 46/100: 100%|██████████| 1131/1131 [00:22<00:00, 51.02it/s, acc=0.738, loss=0.594]\n",
      "Epoch 47/100: 100%|██████████| 1131/1131 [00:22<00:00, 50.98it/s, acc=0.788, loss=0.571]\n",
      "Epoch 48/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.35it/s, acc=0.863, loss=0.585]\n",
      "Epoch 49/100: 100%|██████████| 1131/1131 [00:24<00:00, 45.63it/s, acc=0.775, loss=0.614]\n",
      "Epoch 50/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.49it/s, acc=0.85, loss=0.568] \n",
      "Epoch 51/100: 100%|██████████| 1131/1131 [00:24<00:00, 45.86it/s, acc=0.887, loss=0.534]\n",
      "Epoch 52/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.35it/s, acc=0.875, loss=0.582]\n",
      "Epoch 53/100: 100%|██████████| 1131/1131 [00:22<00:00, 50.64it/s, acc=0.875, loss=0.572]\n",
      "Epoch 54/100: 100%|██████████| 1131/1131 [00:22<00:00, 51.10it/s, acc=0.812, loss=0.605]\n",
      "Epoch 55/100: 100%|██████████| 1131/1131 [00:22<00:00, 51.08it/s, acc=0.85, loss=0.569] \n",
      "Epoch 56/100: 100%|██████████| 1131/1131 [00:24<00:00, 45.56it/s, acc=0.85, loss=0.569] \n",
      "Epoch 57/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.43it/s, acc=0.875, loss=0.563]\n",
      "Epoch 58/100: 100%|██████████| 1131/1131 [00:25<00:00, 44.97it/s, acc=0.762, loss=0.588]\n",
      "Epoch 59/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.99it/s, acc=0.713, loss=0.57] \n",
      "Epoch 60/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.73it/s, acc=0.863, loss=0.558]\n",
      "Epoch 61/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.13it/s, acc=0.875, loss=0.577]\n",
      "Epoch 62/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.30it/s, acc=0.875, loss=0.606]\n",
      "Epoch 63/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.65it/s, acc=0.775, loss=0.65] \n",
      "Epoch 64/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.24it/s, acc=0.788, loss=0.607]\n",
      "Epoch 65/100: 100%|██████████| 1131/1131 [00:24<00:00, 45.40it/s, acc=0.75, loss=0.595] \n",
      "Epoch 66/100: 100%|██████████| 1131/1131 [00:24<00:00, 47.04it/s, acc=0.762, loss=0.601]\n",
      "Epoch 67/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.62it/s, acc=0.788, loss=0.587]\n",
      "Epoch 68/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.15it/s, acc=0.9, loss=0.538]  \n",
      "Epoch 69/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.71it/s, acc=0.85, loss=0.569] \n",
      "Epoch 70/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.75it/s, acc=0.838, loss=0.59] \n",
      "Epoch 71/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.52it/s, acc=0.825, loss=0.561]\n",
      "Epoch 72/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.29it/s, acc=0.838, loss=0.573]\n",
      "Epoch 73/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.77it/s, acc=0.8, loss=0.607]  \n",
      "Epoch 74/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.53it/s, acc=0.863, loss=0.57] \n",
      "Epoch 75/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.60it/s, acc=0.788, loss=0.537]\n",
      "Epoch 76/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.76it/s, acc=0.875, loss=0.575]\n",
      "Epoch 77/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.25it/s, acc=0.875, loss=0.598]\n",
      "Epoch 78/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.29it/s, acc=0.812, loss=0.614]\n",
      "Epoch 79/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.24it/s, acc=0.738, loss=0.57] \n",
      "Epoch 80/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.67it/s, acc=0.8, loss=0.557]  \n",
      "Epoch 81/100: 100%|██████████| 1131/1131 [00:23<00:00, 48.94it/s, acc=0.85, loss=0.585] \n",
      "Epoch 82/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.80it/s, acc=0.863, loss=0.571]\n",
      "Epoch 83/100: 100%|██████████| 1131/1131 [00:22<00:00, 50.06it/s, acc=0.788, loss=0.571]\n",
      "Epoch 84/100: 100%|██████████| 1131/1131 [00:23<00:00, 48.99it/s, acc=0.838, loss=0.531]\n",
      "Epoch 85/100: 100%|██████████| 1131/1131 [00:22<00:00, 49.27it/s, acc=0.838, loss=0.537]\n",
      "Epoch 86/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.20it/s, acc=0.788, loss=0.58] \n",
      "Epoch 87/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.28it/s, acc=0.8, loss=0.6]    \n",
      "Epoch 88/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.27it/s, acc=0.825, loss=0.595]\n",
      "Epoch 89/100: 100%|██████████| 1131/1131 [00:24<00:00, 45.59it/s, acc=0.788, loss=0.574]\n",
      "Epoch 90/100: 100%|██████████| 1131/1131 [00:23<00:00, 47.44it/s, acc=0.812, loss=0.579]\n",
      "Epoch 91/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.60it/s, acc=0.825, loss=0.592]\n",
      "Epoch 92/100: 100%|██████████| 1131/1131 [00:24<00:00, 47.08it/s, acc=0.85, loss=0.602] \n",
      "Epoch 93/100: 100%|██████████| 1131/1131 [00:24<00:00, 45.71it/s, acc=0.788, loss=0.582]\n",
      "Epoch 94/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.43it/s, acc=0.812, loss=0.59] \n",
      "Epoch 95/100: 100%|██████████| 1131/1131 [00:24<00:00, 45.50it/s, acc=0.9, loss=0.565]  \n",
      "Epoch 96/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.50it/s, acc=0.838, loss=0.584]\n",
      "Epoch 97/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.41it/s, acc=0.825, loss=0.615]\n",
      "Epoch 98/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.23it/s, acc=0.788, loss=0.579]\n",
      "Epoch 99/100: 100%|██████████| 1131/1131 [00:24<00:00, 46.79it/s, acc=0.825, loss=0.557]\n",
      "Batch: 100%|██████████| 15012/15012 [00:11<00:00, 1362.79it/s]\n"
     ]
    }
   ],
   "source": [
    "DATASETS_PATH = os.path.sep + os.path.join(\"workspace\", \"dataset_varius_test\")\n",
    "for dataset_folder in os.listdir(DATASETS_PATH):\n",
    "    folder = os.path.join(DATASETS_PATH, dataset_folder)\n",
    "    RESULTS_PATH = os.path.sep + os.path.join(\"workspace\", \"results\", dataset_folder + \"_ANN\")\n",
    "\n",
    "    if not os.path.exists(RESULTS_PATH):\n",
    "        os.makedirs(RESULTS_PATH)\n",
    "\n",
    "    x_train_path = glob.glob(os.path.join(folder, \"dataset\", \"x_train.csv\"))\n",
    "    y_train_path = glob.glob(os.path.join(folder, \"dataset\", \"y_train.csv\"))\n",
    "    x_test_path  = glob.glob(os.path.join(folder, \"dataset\", \"x_test.csv\"))\n",
    "    y_test_path  = glob.glob(os.path.join(folder, \"dataset\", \"y_test.csv\"))\n",
    "\n",
    "    x_train = pd.read_csv(x_train_path[0])\n",
    "    y_train = pd.read_csv(y_train_path[0])\n",
    "    x_test  = pd.read_csv(x_test_path[0])\n",
    "    y_test  = pd.read_csv(y_test_path[0])\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    df_xtrain = pd.read_csv(x_train_path[0])\n",
    "    dir_checkpoint = os.path.join(RESULTS_PATH,\"checkpoints\")\n",
    "    if os.path.exists(dir_checkpoint)==False:\n",
    "        os.mkdir(dir_checkpoint)\n",
    "\n",
    "    batch_size = 128\n",
    "    lr = 0.001\n",
    "    epochs = 100\n",
    "    net = BinaryClassification(df_xtrain.shape[1], n_classes=1, hidden_1=64, hidden_2 = 64, dropout = 0.3, batch_size=batch_size)\n",
    "    net.to(device)\n",
    "\n",
    "    if os.path.exists(os.path.join(RESULTS_PATH,\"checkpoints\",f\"net_epoch_{epochs}.pth\")) == False:\n",
    "        train_net(net,device,x_train_path[0],y_train_path[0], dir_checkpoint, epochs=epochs,batch_size = batch_size, lr = lr)\n",
    "\n",
    "    net.load_state_dict(torch.load(os.path.join(RESULTS_PATH,\"checkpoints\",f\"net_epoch_{epochs}.pth\"), map_location=device))\n",
    "\n",
    "\n",
    "    st = time.time()\n",
    "    y_test, y_pred = prediction(net, device, x_test_path[0], y_test_path[0])\n",
    "    ed = time.time()\n",
    "    ex_time = ed - st\n",
    "    sps = len(y_pred)/ex_time\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=[\"Not Rain\", \"Rain\"])\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    df_res = pd.DataFrame({\"Precision\": [precision], \"Recall\": [recall], \"F1\": [f1], \"Accuracy\": [acc], \"Execution Time\": [ex_time], \"Samples per second\": [sps], \"Classification Report\": [report]})\n",
    "    df_res.to_csv(os.path.join(RESULTS_PATH, \"results.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
